# SoniFree

This project empowers independent podcasters who self-host their audio files and feeds by providing a centralized
dashboard for listening stats and follower/subscriber counts across multiple podcast directories and apps ‚Äî without
being tied to a proprietary publisher or analytics platform. This app can be fully self-hosted.

## Key Features

* üåç Multi-platform Listener Stats Collector
* üë• Standardized Listener, Follower, and Subscriber Data
* üìà Central Dashboard
* üîí Privacy-respecting
* üíª Open Source / Self-hosted

![Screenshot of SoniFree Dashboard, showing graphs going upwards](/resources/screenshot1.png?raw=true "SoniFree Dashboard")

## Why It Matters

Independent podcasters often choose to self-host to:

* Avoid platform lock-in.
* Full control over content and RSS feeds.
* Ensure longevity and portability.

Up until now the tradeoff is losing consolidated analytics, which big platforms provide. This software fills that gap,
giving creators reliable insights without sacrificing independence.

## Supporter Podcast Providers

| Provider      | Scraper          | Normalizer       |
|---------------|------------------|------------------|
| Amazon        | ‚úÖWorking         | ‚úÖWorking         |
| Apple         | üößWIP            | ‚ùåNot Implemented |
| Podbean       | ‚ùåNot Implemented | ‚ùåNot Implemented |
| Spotify       | ‚úÖWorking         | ‚úÖWorking         |
| YouTube Music | ‚ùåNot Implemented | ‚ùåNot Implemented |

## Technical Design

* ü§ñCollector: responsible for scraping data from different Podcast providers.
* üíæStorage: stores responses and metadata.
* üîÑProcessing: responsible for normalizing those responses.
* üìäPresentation: HTML files generated by the previous step to visualize the data.

# Installation

Environment variables necessary for scraper to run:

```
export AMAZON_USER_NAME=amazon@example.com
export AMAZON_PASSWORD=secret123

export APPLE_USER_NAME=applepodcast@example.com
export APPLE_PASSWORD=secret123
export APPLE_APP_ID_KEY=b169e8846a47372cf884957c4a56c9451d29156ee8808a21695cfd530be8d518
export APPLE_PODCAST_ID=1234567890

export SPOTIFY_USER_NAME=spotify@example.com
export SPOTIFY_PASSWORD=secret123
export SPOTIFY_PODCAST_ID=bmV2dmVyIGdvbm5hIGdpXX

export ANTICAPTCHA_API_KEY=344aab9758bb0d018b93739e7893fb3a  # see below

export CHROME_EXECUTABLE_PATH=C:\Program Files\Chromium\Application\chrome.exe
export META_DIR=C:\path\to\meta
export PAYLOAD_DIR=C:\path\to\payload
```

For the processor, you only need the two variables `META_DIR` and `PAYLOAD_DIR`.

## Captchas

This is scraping after all, so captchas are expected. You can deal with it in three ways:

1. Not care: worst case is that you don't get any data for some platforms. Sometimes it works good enough.
2. Set the `ANTICAPTCHA_API_KEY` variable with a key from anti-captcha.com (no affiliation). 1000 solves cost around
   10 bugs by the time of writing.
3. Run the scraper on your system manually. When the `ANTICAPTCHA_API_KEY` is not set the scraper will pause for your
   input when it encounters a captcha.

# Collector

Many of the major platforms where podcasts are distributed ‚Äî Apple, Amazon, Spotify, YouTube ‚Äî are not podcast-first
services. Their APIs are either locked down, incomplete, or non-existent for podcast analytics. As a result, the
Collector cannot simply fetch data basic HTTP requests. Instead, it relies on browser automation to log in, navigate
secure authentication flows, and scrape relevant metrics. This approach makes the system more complex but hopefully also
more stable against changes in Login flows.

The Collector uses Selenium and is tested with Chromium. It further uses the browser performance log to retrieve
payloads while navigating through the different admin interfaces.

The following environment variables need to be set to configure the scraper:

```
CHROME_EXECUTABLE_PATH=C:\Program Files\Chromium\Application\chrome.exe

AMAZON_USER_NAME=foo@examplecom
AMAZON_PASSWORD=bar

SPOTIFY_USER_NAME=foo@examplecom
SPOTIFY_PASSWORD=bar
SPOTIFY_PODCAST_ID=baz
# taken from a podcast URL like https://open.spotify.com/show/baz
```

Ontop of that, you need to configure `META_DIR` and `PAYLOAD_DIR` for storage (see the next section for details).

# Storage

SoniFree currently doesn't have a proper database. It mainly uses two directories: one for metadata and one for captured
payloads in raw form. Raw payloads are kept to decouple scraping from normalization and in particular speed up
development of the normalization part. The following two environment variables can be used to configure the directories:

```
SET META_DIR=X:\SoniFree\MyPodcast\meta
SET PAYLOAD_DIR=X:\SoniFree\MyPodcast\payload
```

The meta-directory has a subdirectory for every year followed by another subdirectory for every month. Inside those
directories, there are files of the form `YYYYMMDD-hhmmss-PROVIDER-PAYLOADSHA256`:

```
meta/2025/09/20250909-111940-Spotify-df55ce3b0b.json
meta/2025/09/20250909-191630-Amazon-1da4318099.json
```

The payload directory stores payloads by their SHA256 hash. It does so by placing them in subdirectories named after
hex-encoded bytes of the hash allow for directory listing in case the number of payloads gets very large.

```
payload\0a\1b\05\0a1b052faa8880e5082d84578216a76f94eacf2ed7f580bae563b51227614ed1
payload\f4\de\87\f4de87260634cb2f99e5339887e52e763338f7d9a8a0d30c012a722a54a0e05b
```

# Processing

The file `process.py` iterates all files from `META_DIR` and then reads payload data from `PAYLOAD_DIR`. Those payloads
are actual responses received while navigating the Podcast provider dashboards/admin interfaces.

# Presentation

Resulting data is represented on auto-generated static HTML pages. Those are generated through `process.py` by
specifying an `OUTPUT_STRATEGY` of `chartjs`. The static HTML page uses [Chart.js](https://www.chartjs.org/) for no
particular reason.
